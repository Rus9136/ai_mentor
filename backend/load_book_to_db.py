#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö —É—á–µ–±–Ω–∏–∫–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö AI Mentor.

–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–Ω–∏–≥—É –∫–∞–∫ –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (school_id=NULL).
–°–æ–∑–¥–∞–µ—Ç: Textbook ‚Üí Chapters ‚Üí Paragraphs

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python load_to_db.py results/–ò—Å—Ç–æ—Ä–∏—è–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞7_–†—É—Å_parsed.json --lang ru
    python load_to_db.py results/–ò—Å—Ç–æ—Ä–∏—è_–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞_–ö–∞–∑_parsed.json --lang kk
"""
import asyncio
import argparse
import json
import re
import sys
import os
from pathlib import Path
from typing import Optional

from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession
from sqlalchemy import select, text

from app.models.textbook import Textbook
from app.models.chapter import Chapter
from app.models.paragraph import Paragraph


# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –£–ß–ï–ë–ù–ò–ö–ê "–ò–°–¢–û–†–ò–Ø –ö–ê–ó–ê–•–°–¢–ê–ù–ê 7 –ö–õ–ê–°–°"
# ============================================================================

TEXTBOOK_CONFIG = {
    "ru": {
        "title": "–ò—Å—Ç–æ—Ä–∏—è –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞ (XVIII-XIX –≤–≤.)",
        "subject": "–ò—Å—Ç–æ—Ä–∏—è –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞",
        "grade_level": 7,
        "author": "–¢. –û–º–∞—Ä–±–µ–∫–æ–≤, –ì.–ë. –•–∞–±–∏–∂–∞–Ω–æ–≤–∞, –¢.–ï. –ö–∞—Ä—Ç–∞–µ–≤–∞, –ú.–°. –ù–æ–≥–∞–π–±–∞–µ–≤–∞, –ì.–ï. –ê–±–∏–∫–µ–Ω–æ–≤–∞",
        "publisher": "–ú–µ–∫—Ç–µ–ø",
        "year": 2025,
        "isbn": "978-601-07-1769-5",
        "description": "–£—á–µ–±–Ω–∏–∫ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞ –¥–ª—è 7 –∫–ª–∞—Å—Å–∞ –æ–±—â–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —à–∫–æ–ª. "
                      "–û—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –ø–µ—Ä–∏–æ–¥ XVIII-XIX –≤–µ–∫–æ–≤: –∫–∞–∑–∞—Ö—Å–∫–æ-–¥–∂—É–Ω–≥–∞—Ä—Å–∫–∏–µ –≤–æ–π–Ω—ã, "
                      "–≤—Ö–æ–∂–¥–µ–Ω–∏–µ –≤ —Å–æ—Å—Ç–∞–≤ –†–æ—Å—Å–∏–π—Å–∫–æ–π –∏–º–ø–µ—Ä–∏–∏, –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ-–æ—Å–≤–æ–±–æ–¥–∏—Ç–µ–ª—å–Ω—ã–µ –¥–≤–∏–∂–µ–Ω–∏—è.",
    },
    "kk": {
        "title": "“ö–∞–∑–∞“õ—Å—Ç–∞–Ω —Ç–∞—Ä–∏—Ö—ã (XVIII-XIX “ì“ì.)",
        "subject": "“ö–∞–∑–∞“õ—Å—Ç–∞–Ω —Ç–∞—Ä–∏—Ö—ã",
        "grade_level": 7,
        "author": "–¢. –û–º–∞—Ä–±–µ–∫–æ–≤, –ì.–ë. –•–∞–±–∏–∂–∞–Ω–æ–≤–∞, –¢.–ï. –ö–∞—Ä—Ç–∞–µ–≤–∞, –ú.–°. –ù–æ–≥–∞–π–±–∞–µ–≤–∞, –ì.–ï. –ê–±–∏–∫–µ–Ω–æ–≤–∞",
        "publisher": "–ú–µ–∫—Ç–µ–ø",
        "year": 2025,
        "isbn": "978-601-07-1769-5",
        "description": "7 —Å—ã–Ω—ã–ø –∂–∞–ª–ø—ã –±—ñ–ª—ñ–º –±–µ—Ä–µ—Ç—ñ–Ω –º–µ–∫—Ç–µ–ø—Ç–µ—Ä—ñ–Ω–µ –∞—Ä–Ω–∞–ª“ì–∞–Ω “ö–∞–∑–∞“õ—Å—Ç–∞–Ω —Ç–∞—Ä–∏—Ö—ã –æ“õ—É–ª—ã“ì—ã.",
    }
}

# –ú–∞–ø–ø–∏–Ω–≥ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –∫ —Ä–∞–∑–¥–µ–ª–∞–º (–∏–∑ –æ–≥–ª–∞–≤–ª–µ–Ω–∏—è)
CHAPTERS_CONFIG = {
    "ru": [
        {
            "number": 1,
            "title": "–ö–∞–∑–∞—Ö—Å–∫–æ-–¥–∂—É–Ω–≥–∞—Ä—Å–∫–∏–µ –≤–æ–π–Ω—ã",
            "description": "–ü—Ä–æ—Ç–∏–≤–æ—Å—Ç–æ—è–Ω–∏–µ –ö–∞–∑–∞—Ö—Å–∫–æ–≥–æ —Ö–∞–Ω—Å—Ç–≤–∞ –∏ –î–∂—É–Ω–≥–∞—Ä–∏–∏ –≤ XVIII –≤–µ–∫–µ",
            "paragraphs": range(1, 7),  # ¬ß1-6
        },
        {
            "number": 2,
            "title": "–ö–∞–∑–∞—Ö—Å–∫–æ–µ —Ö–∞–Ω—Å—Ç–≤–æ –≤ XVIII –≤–µ–∫–µ",
            "description": "–ü–æ–ª–∏—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ –∏ –∫–∞–∑–∞—Ö—Å–∫–æ-—Ä—É—Å—Å–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è",
            "paragraphs": range(7, 15),  # ¬ß7-14
        },
        {
            "number": 3,
            "title": "–ö—É–ª—å—Ç—É—Ä–∞ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞ –≤ XVIII –≤–µ–∫–µ",
            "description": "–î—É—Ö–æ–≤–Ω–∞—è –∫—É–ª—å—Ç—É—Ä–∞, —Ç—Ä–∞–¥–∏—Ü–∏–∏ –∏ –∏—Å–∫—É—Å—Å—Ç–≤–æ",
            "paragraphs": range(15, 19),  # ¬ß15-18
        },
        {
            "number": 4,
            "title": "–ö–æ–ª–æ–Ω–∏–∑–∞—Ü–∏—è –∏ –Ω–∞—Ä–æ–¥–Ω–æ-–æ—Å–≤–æ–±–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è –±–æ—Ä—å–±–∞",
            "description": "–ö–æ–ª–æ–Ω–∏–∞–ª—å–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –∏ –≤–æ—Å—Å—Ç–∞–Ω–∏—è –∫–∞–∑–∞—Ö–æ–≤",
            "paragraphs": range(19, 33),  # ¬ß19-32
        },
        {
            "number": 5,
            "title": "–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω –≤ —Å–æ—Å—Ç–∞–≤–µ –†–æ—Å—Å–∏–π—Å–∫–æ–π –∏–º–ø–µ—Ä–∏–∏",
            "description": "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ä–µ—Ñ–æ—Ä–º—ã –∏ —Å–æ—Ü–∏–∞–ª—å–Ω–æ-—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è",
            "paragraphs": range(33, 46),  # ¬ß33-45
        },
        {
            "number": 6,
            "title": "–ö—É–ª—å—Ç—É—Ä–∞ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞ –≤ XIX - –Ω–∞—á–∞–ª–µ XX –≤–µ–∫–∞",
            "description": "–ü—Ä–æ—Å–≤–µ—â–µ–Ω–∏–µ, –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞, –Ω–∞—É–∫–∞ –∏ –∏—Å–∫—É—Å—Å—Ç–≤–æ",
            "paragraphs": range(46, 61),  # ¬ß46-60
        },
    ],
    "kk": [
        {
            "number": 1,
            "title": "“ö–∞–∑–∞“õ-–∂–æ“£“ì–∞—Ä —Å–æ“ì—ã—Å—Ç–∞—Ä—ã",
            "description": "XVIII “ì–∞—Å—ã—Ä–¥–∞“ì—ã “ö–∞–∑–∞“õ —Ö–∞–Ω–¥—ã“ì—ã –º–µ–Ω –ñ–æ“£“ì–∞—Ä–∏—è –∞—Ä–∞—Å—ã–Ω–¥–∞“ì—ã “õ–∞—Ä—Å—ã–ª—ã“õ",
            "paragraphs": range(1, 7),
        },
        {
            "number": 2,
            "title": "XVIII “ì–∞—Å—ã—Ä–¥–∞“ì—ã “ö–∞–∑–∞“õ —Ö–∞–Ω–¥—ã“ì—ã",
            "description": "–°–∞—è—Å–∏ –¥–∞–º—É –∂”ô–Ω–µ “õ–∞–∑–∞“õ-–æ—Ä—ã—Å “õ–∞—Ç—ã–Ω–∞—Å—Ç–∞—Ä—ã",
            "paragraphs": range(7, 15),
        },
        {
            "number": 3,
            "title": "XVIII “ì–∞—Å—ã—Ä–¥–∞“ì—ã “ö–∞–∑–∞“õ—Å—Ç–∞–Ω –º”ô–¥–µ–Ω–∏–µ—Ç—ñ",
            "description": "–†—É—Ö–∞–Ω–∏ –º”ô–¥–µ–Ω–∏–µ—Ç, –¥”ô—Å—Ç“Ø—Ä–ª–µ—Ä –∂”ô–Ω–µ ”©–Ω–µ—Ä",
            "paragraphs": range(15, 19),
        },
        {
            "number": 4,
            "title": "–û—Ç–∞—Ä–ª–∞—É –∂”ô–Ω–µ “±–ª—Ç-–∞–∑–∞—Ç—Ç—ã“õ “õ–æ–∑“ì–∞–ª—ã—Å",
            "description": "–û—Ç–∞—Ä–ª—ã“õ —Å–∞—è—Å–∞—Ç –∂”ô–Ω–µ “õ–∞–∑–∞“õ—Ç–∞—Ä–¥—ã“£ –∫”©—Ç–µ—Ä—ñ–ª—ñ—Å—Ç–µ—Ä—ñ",
            "paragraphs": range(19, 33),
        },
        {
            "number": 5,
            "title": "–†–µ—Å–µ–π –∏–º–ø–µ—Ä–∏—è—Å—ã “õ“±—Ä–∞–º—ã–Ω–¥–∞“ì—ã “ö–∞–∑–∞“õ—Å—Ç–∞–Ω",
            "description": "”ò–∫—ñ–º—à—ñ–ª—ñ–∫ —Ä–µ—Ñ–æ—Ä–º–∞–ª–∞—Ä –∂”ô–Ω–µ ”ô–ª–µ—É–º–µ—Ç—Ç—ñ–∫-—ç–∫–æ–Ω–æ–º–∏–∫–∞–ª—ã“õ ”©–∑–≥–µ—Ä—ñ—Å—Ç–µ—Ä",
            "paragraphs": range(33, 46),
        },
        {
            "number": 6,
            "title": "XIX - XX “ì–∞—Å—ã—Ä –±–∞—Å—ã–Ω–¥–∞“ì—ã “ö–∞–∑–∞“õ—Å—Ç–∞–Ω –º”ô–¥–µ–Ω–∏–µ—Ç—ñ",
            "description": "–ê“ì–∞—Ä—Ç—É, ”ô–¥–µ–±–∏–µ—Ç, “ì—ã–ª—ã–º –∂”ô–Ω–µ ”©–Ω–µ—Ä",
            "paragraphs": range(46, 61),
        },
    ]
}


# ============================================================================
# –§–£–ù–ö–¶–ò–ò –û–ë–†–ê–ë–û–¢–ö–ò –î–ê–ù–ù–´–•
# ============================================================================

def extract_paragraph_number(title: str) -> Optional[int]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞.

    –ü—Ä–∏–º–µ—Ä—ã:
        "$ 1. –í–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ..." ‚Üí 1
        "¬ß 5. –ê–Ω—Ä–∞–∫–∞–π—Å–∫–∞—è –±–∏—Ç–≤–∞..." ‚Üí 5
        "$12 –°—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ê–±—ã–ª–∞–π —Ö–∞–Ω–∞..." ‚Üí 12
        "$ 7-8. –ö–∞–∑–∞—Ö—Å–∫–æ-—Ä—É—Å—Å–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è..." ‚Üí 7
        "5 9. –ü—Ä–∏—á–∏–Ω—ã –∏ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è..." ‚Üí 9 (OCR –æ—à–∏–±–∫–∞: ¬ß‚Üí5)
        "8 21-22. –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ-–æ—Å–≤–æ–±–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ..." ‚Üí 21 (OCR –æ—à–∏–±–∫–∞: ¬ß‚Üí8)
    """
    # –ü–∞—Ç—Ç–µ—Ä–Ω: $ –∏–ª–∏ ¬ß + –Ω–æ–º–µ—Ä
    match = re.match(r'^[¬ß$]\s*(\d+)', title)
    if match:
        return int(match.group(1))
    # OCR –æ—à–∏–±–∫–∞: ¬ß —Ä–∞—Å–ø–æ–∑–Ω–∞—ë—Ç—Å—è –∫–∞–∫ 5 –∏–ª–∏ 8
    match = re.match(r'^[58]\s+(\d+)', title)
    if match:
        return int(match.group(1))
    return None


def clean_paragraph_title(title: str) -> str:
    """
    –û—á–∏—â–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –æ—Ç —Å–∏–º–≤–æ–ª–æ–≤ ¬ß –∏ $.

    "$ 1. –í–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ..." ‚Üí "–í–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ..."
    "5 9. –ü—Ä–∏—á–∏–Ω—ã..." ‚Üí "–ü—Ä–∏—á–∏–Ω—ã..." (OCR –æ—à–∏–±–∫–∞)
    """
    # –£–±–∏—Ä–∞–µ–º "$ N." –∏–ª–∏ "¬ß N." –∏–∑ –Ω–∞—á–∞–ª–∞
    cleaned = re.sub(r'^[¬ß$]\s*\d+[-\d]*\.\s*', '', title)
    # OCR –æ—à–∏–±–∫–∞: "5 N." –∏–ª–∏ "8 N."
    cleaned = re.sub(r'^[58]\s+\d+[-\d]*\.\s*', '', cleaned)
    # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–æ—Å—å –ø—É—Å—Ç–æ –∏–ª–∏ —Ç–æ–ª—å–∫–æ –Ω–æ–º–µ—Ä
    if not cleaned or re.match(r'^\d+$', cleaned):
        return title
    return cleaned.strip()


def extract_content_and_questions(content_items: list) -> tuple[str, list]:
    """
    –†–∞–∑–¥–µ–ª—è–µ—Ç content –Ω–∞ —Ç–µ–∫—Å—Ç –∏ –≤–æ–ø—Ä–æ—Å—ã.

    Returns:
        (full_text, questions_list)
    """
    text_parts = []
    questions = []
    question_order = 1

    for item in content_items:
        item_type = item.get('type', 'text')
        item_text = item.get('text', '').strip()

        if not item_text:
            continue

        if item_type == 'question':
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
            q_match = re.match(r'^(\d+)\.\s*(.+)', item_text)
            if q_match:
                q_text = q_match.group(2)
            else:
                q_text = item_text

            questions.append({
                "order": question_order,
                "text": q_text
            })
            question_order += 1

        elif item_type in ('text', 'subtitle'):
            text_parts.append(item_text)

        elif item_type == 'task':
            # –ó–∞–¥–∞–Ω–∏—è —Ç–æ–∂–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Ç–µ–∫—Å—Ç
            text_parts.append(f"\n[–ó–∞–¥–∞–Ω–∏–µ] {item_text}")

        elif item_type == 'source':
            text_parts.append(f"\n[–ò—Å—Ç–æ—á–Ω–∏–∫] {item_text}")

        elif item_type == 'image':
            text_parts.append(f"\n[–ò–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è: {item_text}]")

        elif item_type == 'table':
            text_parts.append(f"\n[–¢–∞–±–ª–∏—Ü–∞: {item_text}]")

    full_text = '\n'.join(text_parts)
    return full_text, questions


def find_chapter_for_paragraph(para_num: int, chapters_config: list) -> Optional[dict]:
    """–ù–∞—Ö–æ–¥–∏—Ç —Ä–∞–∑–¥–µ–ª –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –Ω–æ–º–µ—Ä–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞."""
    for chapter in chapters_config:
        if para_num in chapter['paragraphs']:
            return chapter
    return None


def transform_parsed_data(parsed_data: list, lang: str) -> dict:
    """
    –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–∞—Ä—Å–µ—Ä–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î.

    Returns:
        {
            "textbook": {...},
            "chapters": [
                {
                    "number": 1,
                    "title": "...",
                    "paragraphs": [
                        {"number": 1, "title": "...", "content": "...", "questions": [...]}
                    ]
                }
            ]
        }
    """
    chapters_config = CHAPTERS_CONFIG[lang]
    textbook_config = TEXTBOOK_CONFIG[lang]

    # –°–æ–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã –∏–∑ parsed_data
    # –í–ê–ñ–ù–û: –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—Ü–∏–π —Å –æ–¥–Ω–∏–º –Ω–æ–º–µ—Ä–æ–º (–æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ + —Ä–µ–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç)
    # –ë–µ—Ä–µ–º –≤–µ—Ä—Å–∏—é —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
    parsed_paragraphs = {}
    for section in parsed_data:
        if section.get('type') != 'paragraph':
            continue

        title = section.get('title', '')
        para_num = extract_paragraph_number(title)

        if para_num is None:
            continue

        content_items = section.get('content', [])
        full_text, questions = extract_content_and_questions(content_items)

        # –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –ø–∞—Ä–∞–≥—Ä–∞—Ñ —Å —Ç–∞–∫–∏–º –Ω–æ–º–µ—Ä–æ–º - –±–µ—Ä–µ–º —Ç–æ—Ç, —á—Ç–æ –¥–ª–∏–Ω–Ω–µ–µ
        if para_num in parsed_paragraphs:
            existing_len = len(parsed_paragraphs[para_num]['content'])
            if len(full_text) <= existing_len:
                continue  # –¢–µ–∫—É—â–∏–π –∫–æ—Ä–æ—á–µ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º

        parsed_paragraphs[para_num] = {
            "number": para_num,
            "title": clean_paragraph_title(title),
            "content": full_text,
            "questions": questions if questions else None,
            "page": section.get('page'),
        }

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∞–∑–¥–µ–ª–æ–≤
    chapters = []
    for chapter_cfg in chapters_config:
        chapter_paragraphs = []

        for para_num in chapter_cfg['paragraphs']:
            if para_num in parsed_paragraphs:
                chapter_paragraphs.append(parsed_paragraphs[para_num])

        chapters.append({
            "number": chapter_cfg['number'],
            "title": chapter_cfg['title'],
            "description": chapter_cfg.get('description'),
            "paragraphs": chapter_paragraphs,
        })

    return {
        "textbook": textbook_config,
        "chapters": chapters,
    }


# ============================================================================
# –ó–ê–ì–†–£–ó–ö–ê –í –ë–î
# ============================================================================

async def load_to_database(data: dict, db_url: str, dry_run: bool = False):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É."""

    engine = create_async_engine(db_url, echo=False)
    async_session = async_sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)

    async with async_session() as session:
        print("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —É—á–µ–±–Ω–∏–∫–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
        print("=" * 60)

        textbook_data = data['textbook']
        chapters_data = data['chapters']

        if dry_run:
            print("üîç DRY RUN - –¥–∞–Ω–Ω—ã–µ –ù–ï –±—É–¥—É—Ç –∑–∞–ø–∏—Å–∞–Ω—ã –≤ –ë–î")
            print()

        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–æ–≥–æ —É—á–µ–±–Ω–∏–∫–∞
        existing = await session.execute(
            select(Textbook).where(
                Textbook.title == textbook_data['title'],
                Textbook.school_id.is_(None),
                Textbook.is_deleted == False
            )
        )
        if existing.scalar_one_or_none():
            print(f"‚ö†Ô∏è  –£—á–µ–±–Ω–∏–∫ '{textbook_data['title']}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
            print("   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --force –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏")
            return

        # 2. –°–æ–∑–¥–∞–µ–º —É—á–µ–±–Ω–∏–∫
        textbook = Textbook(
            school_id=None,  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
            title=textbook_data['title'],
            subject=textbook_data['subject'],
            grade_level=textbook_data['grade_level'],
            author=textbook_data.get('author'),
            publisher=textbook_data.get('publisher'),
            year=textbook_data.get('year'),
            isbn=textbook_data.get('isbn'),
            description=textbook_data.get('description'),
            is_active=True,
        )

        print(f"üìñ –£—á–µ–±–Ω–∏–∫: {textbook.title}")
        print(f"   –ü—Ä–µ–¥–º–µ—Ç: {textbook.subject}, –ö–ª–∞—Å—Å: {textbook.grade_level}")
        print()

        if not dry_run:
            session.add(textbook)
            await session.flush()  # –ü–æ–ª—É—á–∞–µ–º ID

        # 3. –°–æ–∑–¥–∞–µ–º —Ä–∞–∑–¥–µ–ª—ã –∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        total_paragraphs = 0
        total_questions = 0

        for chapter_data in chapters_data:
            chapter = Chapter(
                textbook_id=textbook.id if not dry_run else 0,
                title=chapter_data['title'],
                number=chapter_data['number'],
                order=chapter_data['number'],
                description=chapter_data.get('description'),
            )

            para_count = len(chapter_data['paragraphs'])
            q_count = sum(
                len(p.get('questions') or [])
                for p in chapter_data['paragraphs']
            )

            print(f"  üìÅ –†–∞–∑–¥–µ–ª {chapter_data['number']}: {chapter_data['title']}")
            print(f"     –ü–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {para_count}, –í–æ–ø—Ä–æ—Å–æ–≤: {q_count}")

            if not dry_run:
                session.add(chapter)
                await session.flush()

            # –ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã
            for idx, para_data in enumerate(chapter_data['paragraphs']):
                paragraph = Paragraph(
                    chapter_id=chapter.id if not dry_run else 0,
                    title=para_data['title'],
                    number=para_data['number'],
                    order=idx + 1,
                    content=para_data['content'],
                    questions=para_data.get('questions'),
                )

                if not dry_run:
                    session.add(paragraph)

                total_paragraphs += 1
                total_questions += len(para_data.get('questions') or [])

        print()
        print("=" * 60)
        print(f"üìä –ò—Ç–æ–≥–æ:")
        print(f"   –†–∞–∑–¥–µ–ª–æ–≤: {len(chapters_data)}")
        print(f"   –ü–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {total_paragraphs}")
        print(f"   –í–æ–ø—Ä–æ—Å–æ–≤: {total_questions}")

        if not dry_run:
            await session.commit()
            print()
            print(f"‚úÖ –£—á–µ–±–Ω–∏–∫ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω! ID: {textbook.id}")
        else:
            print()
            print("üîç DRY RUN –∑–∞–≤–µ—Ä—à–µ–Ω. –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —É–±–µ—Ä–∏—Ç–µ —Ñ–ª–∞–≥ --dry-run")


# ============================================================================
# MAIN
# ============================================================================

async def main():
    parser = argparse.ArgumentParser(
        description='–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω–æ–≥–æ —É—á–µ–±–Ω–∏–∫–∞ –≤ –ë–î AI Mentor'
    )
    parser.add_argument(
        'input_file',
        help='–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞'
    )
    parser.add_argument(
        '--lang', '-l',
        choices=['ru', 'kk'],
        default='ru',
        help='–Ø–∑—ã–∫ —É—á–µ–±–Ω–∏–∫–∞: ru (—Ä—É—Å—Å–∫–∏–π) –∏–ª–∏ kk (–∫–∞–∑–∞—Ö—Å–∫–∏–π)'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–æ, –±–µ–∑ –∑–∞–ø–∏—Å–∏ –≤ –ë–î'
    )
    # –°–æ–±–∏—Ä–∞–µ–º URL –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º default
    default_db_url = os.getenv(
        'DATABASE_URL',
        f"postgresql+asyncpg://{os.getenv('POSTGRES_USER', 'ai_mentor_user')}:"
        f"{os.getenv('POSTGRES_PASSWORD', 'ai_mentor_pass')}@"
        f"{os.getenv('POSTGRES_HOST', 'localhost')}:"
        f"{os.getenv('POSTGRES_PORT', '5432')}/"
        f"{os.getenv('POSTGRES_DB', 'ai_mentor_db')}"
    )

    parser.add_argument(
        '--db-url',
        default=default_db_url,
        help='URL –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö'
    )

    args = parser.parse_args()

    # –ß–∏—Ç–∞–µ–º JSON
    input_path = Path(args.input_file)
    if not input_path.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
        sys.exit(1)

    print(f"üìÇ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {input_path}")
    with open(input_path, 'r', encoding='utf-8') as f:
        parsed_data = json.load(f)

    print(f"   –°–µ–∫—Ü–∏–π –≤ —Ñ–∞–π–ª–µ: {len(parsed_data)}")
    print()

    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    transformed = transform_parsed_data(parsed_data, args.lang)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ –ë–î
    await load_to_database(transformed, args.db_url, dry_run=args.dry_run)


if __name__ == '__main__':
    asyncio.run(main())
