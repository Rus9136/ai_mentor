#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —É—á–µ–±–Ω–∏–∫–∞ (structured_book_kz.json) –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

–§–æ—Ä–º–∞—Ç JSON:
{
    "textbook": {...},
    "chapters": [
        {
            "number": 1,
            "title": "...",
            "paragraphs": [
                {
                    "number": 1,
                    "title": "...",
                    "learning_objective": "...",
                    "key_terms": [...],
                    "content": "...",
                    "questions": [...]
                }
            ]
        }
    ]
}

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python load_structured_book.py books/output/structured_book_kz.json
"""
import asyncio
import argparse
import json
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º backend –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent / "backend"))

from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession
from sqlalchemy import select

from app.models.textbook import Textbook
from app.models.chapter import Chapter
from app.models.paragraph import Paragraph


async def load_to_database(data: dict, db_url: str, dry_run: bool = False):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É."""

    engine = create_async_engine(db_url, echo=False)
    async_session = async_sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)

    async with async_session() as session:
        print("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —É—á–µ–±–Ω–∏–∫–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
        print("=" * 60)

        textbook_data = data['textbook']
        chapters_data = data['chapters']

        if dry_run:
            print("üîç DRY RUN - –¥–∞–Ω–Ω—ã–µ –ù–ï –±—É–¥—É—Ç –∑–∞–ø–∏—Å–∞–Ω—ã –≤ –ë–î")
            print()

        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–æ–≥–æ —É—á–µ–±–Ω–∏–∫–∞
        existing = await session.execute(
            select(Textbook).where(
                Textbook.title == textbook_data['title'],
                Textbook.school_id.is_(None),
                Textbook.is_deleted == False
            )
        )
        if existing.scalar_one_or_none():
            print(f"‚ö†Ô∏è  –£—á–µ–±–Ω–∏–∫ '{textbook_data['title']}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
            print("   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --force –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ –∏–ª–∏ —É–¥–∞–ª–∏—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π")
            return None

        # 2. –°–æ–∑–¥–∞–µ–º —É—á–µ–±–Ω–∏–∫
        textbook = Textbook(
            school_id=None,  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
            title=textbook_data['title'],
            subject=textbook_data['subject'],
            grade_level=textbook_data['grade_level'],
            author=textbook_data.get('authors', textbook_data.get('author')),
            publisher=textbook_data.get('publisher'),
            year=textbook_data.get('year'),
            isbn=textbook_data.get('isbn'),
            description=textbook_data.get('description'),
            is_active=True,
        )

        print(f"üìñ –£—á–µ–±–Ω–∏–∫: {textbook.title}")
        print(f"   –ü—Ä–µ–¥–º–µ—Ç: {textbook.subject}, –ö–ª–∞—Å—Å: {textbook.grade_level}")
        print(f"   –ê–≤—Ç–æ—Ä: {textbook.author}")
        print(f"   –ò–∑–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ: {textbook.publisher}, –ì–æ–¥: {textbook.year}")
        print()

        if not dry_run:
            session.add(textbook)
            await session.flush()  # –ü–æ–ª—É—á–∞–µ–º ID

        # 3. –°–æ–∑–¥–∞–µ–º —Ä–∞–∑–¥–µ–ª—ã –∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        total_paragraphs = 0
        total_questions = 0

        for chapter_data in chapters_data:
            # –ù–æ–º–µ—Ä –≥–ª–∞–≤—ã –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∏–º—Å–∫–∏–º —á–∏—Å–ª–æ–º –≤ title
            chapter_num = chapter_data.get('number', 1)
            if isinstance(chapter_num, str):
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–∏–º—Å–∫–∏–µ —á–∏—Å–ª–∞
                roman_map = {'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5, 'VI': 6}
                chapter_num = roman_map.get(chapter_num, int(chapter_num) if chapter_num.isdigit() else 1)

            chapter = Chapter(
                textbook_id=textbook.id if not dry_run else 0,
                title=chapter_data['title'],
                number=chapter_num,
                order=chapter_num,
                description=chapter_data.get('description'),
            )

            paragraphs_list = chapter_data.get('paragraphs', [])
            para_count = len(paragraphs_list)
            q_count = sum(
                len(p.get('questions') or [])
                for p in paragraphs_list
            )

            print(f"  üìÅ –†–∞–∑–¥–µ–ª {chapter_num}: {chapter_data['title']}")
            print(f"     –ü–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {para_count}, –í–æ–ø—Ä–æ—Å–æ–≤: {q_count}")

            if not dry_run:
                session.add(chapter)
                await session.flush()

            # –ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã
            for idx, para_data in enumerate(paragraphs_list):
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ key_terms - –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø–∏—Å–æ–∫
                key_terms = para_data.get('key_terms', [])
                if isinstance(key_terms, list):
                    key_terms_json = json.dumps(key_terms, ensure_ascii=False)
                else:
                    key_terms_json = key_terms

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ questions - –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫
                questions = para_data.get('questions', [])
                if isinstance(questions, list) and questions:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –ë–î
                    questions_formatted = [
                        {"order": i+1, "text": q} if isinstance(q, str) else q
                        for i, q in enumerate(questions)
                    ]
                else:
                    questions_formatted = None

                paragraph = Paragraph(
                    chapter_id=chapter.id if not dry_run else 0,
                    title=para_data['title'],
                    number=para_data.get('number', idx + 1),
                    order=idx + 1,
                    content=para_data.get('content', ''),
                    learning_objective=para_data.get('learning_objective'),
                    key_terms=key_terms_json if key_terms else None,
                    questions=questions_formatted,
                )

                if not dry_run:
                    session.add(paragraph)

                total_paragraphs += 1
                total_questions += len(questions)

        print()
        print("=" * 60)
        print(f"üìä –ò—Ç–æ–≥–æ:")
        print(f"   –†–∞–∑–¥–µ–ª–æ–≤: {len(chapters_data)}")
        print(f"   –ü–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {total_paragraphs}")
        print(f"   –í–æ–ø—Ä–æ—Å–æ–≤: {total_questions}")

        if not dry_run:
            await session.commit()
            print()
            print(f"‚úÖ –£—á–µ–±–Ω–∏–∫ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω! ID: {textbook.id}")
            return textbook.id
        else:
            print()
            print("üîç DRY RUN –∑–∞–≤–µ—Ä—à–µ–Ω. –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —É–±–µ—Ä–∏—Ç–µ —Ñ–ª–∞–≥ --dry-run")
            return None


async def main():
    parser = argparse.ArgumentParser(
        description='–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —É—á–µ–±–Ω–∏–∫–∞ –≤ –ë–î AI Mentor'
    )
    parser.add_argument(
        'input_file',
        help='–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —É—á–µ–±–Ω–∏–∫–æ–º'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–æ, –±–µ–∑ –∑–∞–ø–∏—Å–∏ –≤ –ë–î'
    )
    parser.add_argument(
        '--db-url',
        default='postgresql+asyncpg://ai_mentor_user:ai_mentor_pass@localhost:5433/ai_mentor_db',
        help='URL –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö'
    )

    args = parser.parse_args()

    # –ß–∏—Ç–∞–µ–º JSON
    input_path = Path(args.input_file)
    if not input_path.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
        sys.exit(1)

    print(f"üìÇ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {input_path}")
    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç
    if 'textbook' not in data or 'chapters' not in data:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç JSON. –û–∂–∏–¥–∞–µ—Ç—Å—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å 'textbook' –∏ 'chapters'")
        sys.exit(1)

    print(f"   –ì–ª–∞–≤ –≤ —Ñ–∞–π–ª–µ: {len(data['chapters'])}")
    total_p = sum(len(ch.get('paragraphs', [])) for ch in data['chapters'])
    print(f"   –ü–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {total_p}")
    print()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ –ë–î
    await load_to_database(data, args.db_url, dry_run=args.dry_run)


if __name__ == '__main__':
    asyncio.run(main())
