#!/usr/bin/env python3
"""
Structured book parser for OCR text
Identifies paragraphs, questions, tasks, and content types
"""
import re
import json
import os

def classify_line(line):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Å—Ç—Ä–æ–∫–∏."""
    line = line.strip()

    if not line:
        return "empty"

    # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    if re.match(r"^[‚îÄ‚ïê-]{10,}$", line):
        return "separator"

    # –ú–∞—Ä–∫–µ—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü [–°—Ç—Ä–∞–Ω–∏—Ü–∞ N]
    if re.match(r"^\[–°—Ç—Ä–∞–Ω–∏—Ü–∞ \d+\]$", line):
        return "page_marker"

    # –ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã: $ 1., ¬ß 5., $12, ¬ß14
    # –¢–∞–∫–∂–µ –ª–æ–≤–∏–º OCR –æ—à–∏–±–∫–∏: 5 9. (¬ß‚Üí5), 8 21. (¬ß‚Üí8)
    if re.match(r"^[¬ß$]\s*\d+", line):
        return "paragraph"
    # OCR –æ—à–∏–±–∫–∞: ¬ß —Ä–∞—Å–ø–æ–∑–Ω–∞—ë—Ç—Å—è –∫–∞–∫ 5 –∏–ª–∏ 8
    if re.match(r"^[58]\s+\d+[-\d]*\.", line):
        return "paragraph"

    # –ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏ (—á–∞—Å—Ç–æ –∏–¥—É—Ç –±–æ–ª—å—à–∏–º —à—Ä–∏—Ñ—Ç–æ–º, –¥–ª–∏–Ω–Ω—ã–µ, –±–µ–∑ —Ç–æ—á–∫–∏)
    # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –Ω–∞ –∫–∞–∑–∞—Ö—Å–∫–æ–º/—Ä—É—Å—Å–∫–æ–º
    if re.match(r"^[A-Z–ê-–Ø”ò”®“∞“Æ“ö“¢–Ü–Å][A-Za-z–ê-–Ø–∞-—è”ò”ô”®”©“∞“±“Æ“Ø“ö“õ“¢“£–Ü—ñ–Å—ë ,¬´¬ª\"-]{8,}$", line):
        # –ò—Å–∫–ª—é—á–∞–µ–º –æ–±—ã—á–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (—Å–æ–¥–µ—Ä–∂–∞—Ç –º–Ω–æ–≥–æ –º–∞–ª–µ–Ω—å–∫–∏—Ö —Å–ª–æ–≤)
        if not re.search(r"\s(–∏|–≤|–Ω–∞|—Å|—É|–æ|–∞|–Ω–æ|–¥–∞|–∏–ª–∏|–∫|–ø–æ|–æ—Ç|–∑–∞|–¥–æ|–∏–∑|–ø—Ä–∏)\s", line, re.IGNORECASE):
            return "subtitle"

    # –ù—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã: "1. –¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞?"
    if re.match(r"^\d+\.\s+.+", line):
        return "question"

    # –ó–∞–¥–∞–Ω–∏—è (—Ç–æ–ø—Ç—ã“õ, –∂“±–ø—Ç—ã“õ + —Ä—É—Å—Å–∫–∏–µ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç—ã)
    if re.search(r"(–¢–æ–ø—Ç—ã“õ –∂“±–º—ã—Å|–ñ“±–ø—Ç—ã“õ –∂“±–º—ã—Å|–¢–∞–ø—Å—ã—Ä–º–∞|–°“±—Ä–∞“õ—Ç–∞—Ä|–ì—Ä—É–ø–ø–æ–≤–∞—è —Ä–∞–±–æ—Ç–∞|–ü–∞—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞|–ó–∞–¥–∞–Ω–∏–µ|–í–æ–ø—Ä–æ—Å—ã)", line, re.IGNORECASE):
        return "task"

    # –ò—Å—Ç–æ—á–Ω–∏–∫–∏
    if re.match(r"^(–î–µ—Ä–µ–∫.*|Source.*|–ö”©–∑.*|–ò—Å—Ç–æ—á–Ω–∏–∫.*)", line, re.IGNORECASE):
        return "source"

    # –ò–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏
    if re.match(r"^(–°—É—Ä–µ—Ç.*|–†–∏—Å\.|–†–∏—Å—É–Ω–æ–∫.*)", line, re.IGNORECASE):
        return "image"

    # –¢–∞–±–ª–∏—Ü–∞
    if re.match(r"^(–ö–µ—Å—Ç–µ.*|–¢–∞–±–ª–∏—Ü–∞.*)", line, re.IGNORECASE):
        return "table"

    # –î–ª–∏–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–ê–õ“í–´ –°”®–ó –∏ —Ç.–¥.)
    if len(line) < 50 and line.isupper() and len(line.split()) <= 5:
        return "chapter_title"

    return "text"


def parse_book(text):
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç OCR —É—á–µ–±–Ω–∏–∫–∞
    –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç –∫–Ω–∏–≥–∏.
    """

    book = []
    current_paragraph = None
    current_page = None

    for raw_line in text.splitlines():
        line = raw_line.strip()

        if not line:
            continue

        line_type = classify_line(line)

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        if line_type in ["separator", "empty"]:
            continue

        # –ú–∞—Ä–∫–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        if line_type == "page_marker":
            page_match = re.search(r"\[–°—Ç—Ä–∞–Ω–∏—Ü–∞ (\d+)\]", line)
            if page_match:
                current_page = int(page_match.group(1))
            continue

        # –ù–æ–≤—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ
        if line_type == "paragraph":
            current_paragraph = {
                "type": "paragraph",
                "title": line,
                "page": current_page,
                "content": []
            }
            book.append(current_paragraph)
            continue

        # –ù–æ–≤–∞—è –≥–ª–∞–≤–∞ (–±–æ–ª—å—à–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏)
        if line_type == "chapter_title":
            current_paragraph = {
                "type": "chapter",
                "title": line,
                "page": current_page,
                "content": []
            }
            book.append(current_paragraph)
            continue

        # –ö–æ–≥–¥–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ/–≥–ª–∞–≤–∞ –µ—Å—Ç—å ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –≤–Ω—É—Ç—Ä—å
        if current_paragraph:
            current_paragraph["content"].append({
                "type": line_type,
                "text": line,
                "page": current_page
            })
        else:
            # –¢–µ–∫—Å—Ç –¥–æ –ø–µ—Ä–≤–æ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ (–≤–≤–µ–¥–µ–Ω–∏–µ, –æ–±–ª–æ–∂–∫–∞ –∏ —Ç.–¥.)
            if not book or book[-1].get("title") != "INTRO":
                book.append({
                    "type": "intro",
                    "title": "INTRO",
                    "page": current_page,
                    "content": []
                })
            book[-1]["content"].append({
                "type": line_type,
                "text": line,
                "page": current_page
            })

    return book


def save_as_json(book, filename="parsed_book.json"):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."""
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(book, f, ensure_ascii=False, indent=2)
    print(f"‚úÖ JSON —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {filename}")


def save_as_text(book, filename="parsed_book.txt"):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —á–∏—Ç–∞–µ–º–æ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ."""
    with open(filename, "w", encoding="utf-8") as f:
        for section in book:
            section_type = section.get('type', 'unknown')
            page = section.get('page', '?')

            f.write(f"\n{'‚ïê' * 70}\n")
            f.write(f"[{section_type.upper()}] {section['title']} (—Å—Ç—Ä. {page})\n")
            f.write(f"{'‚ïê' * 70}\n\n")

            for item in section.get('content', []):
                item_type = item.get('type', 'text')
                item_page = item.get('page', '?')
                text = item.get('text', '')

                if item_type == "question":
                    f.write(f"\n‚ùì {text}\n")
                elif item_type == "task":
                    f.write(f"\nüìù {text}\n")
                elif item_type == "subtitle":
                    f.write(f"\n‚ñ∂ {text}\n")
                elif item_type == "source":
                    f.write(f"\nüìö {text}\n")
                elif item_type == "image":
                    f.write(f"\nüñºÔ∏è  {text}\n")
                elif item_type == "table":
                    f.write(f"\nüìä {text}\n")
                else:
                    f.write(f"{text}\n")

    print(f"‚úÖ –¢–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {filename}")


def print_statistics(book):
    """–í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω–æ–π –∫–Ω–∏–≥–µ."""
    total_sections = len(book)

    # –ü–æ–¥—Å—á—ë—Ç —Ç–∏–ø–æ–≤ —Å–µ–∫—Ü–∏–π
    chapters = sum(1 for s in book if s.get('type') == 'chapter')
    paragraphs = sum(1 for s in book if s.get('type') == 'paragraph')

    # –ü–æ–¥—Å—á—ë—Ç —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    questions = sum(
        sum(1 for item in s.get('content', []) if item.get('type') == 'question')
        for s in book
    )
    tasks = sum(
        sum(1 for item in s.get('content', []) if item.get('type') == 'task')
        for s in book
    )
    subtitles = sum(
        sum(1 for item in s.get('content', []) if item.get('type') == 'subtitle')
        for s in book
    )

    print("\n" + "‚ïê" * 70)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–ê–†–°–ò–ù–ì–ê")
    print("‚ïê" * 70)
    print(f"–í—Å–µ–≥–æ —Å–µ–∫—Ü–∏–π: {total_sections}")
    print(f"  ‚îú‚îÄ –ì–ª–∞–≤: {chapters}")
    print(f"  ‚îî‚îÄ –ü–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {paragraphs}")
    print(f"\n–≠–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞:")
    print(f"  ‚îú‚îÄ –í–æ–ø—Ä–æ—Å–æ–≤: {questions}")
    print(f"  ‚îú‚îÄ –ó–∞–¥–∞–Ω–∏–π: {tasks}")
    print(f"  ‚îî‚îÄ –ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤: {subtitles}")
    print("‚ïê" * 70 + "\n")


# -------------------------
# üî• –ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –∑–∞–ø—É—Å–∫–∞
# -------------------------

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Parse OCR text into structured format')
    parser.add_argument('input_file', nargs='?', help='Path to input text file')
    parser.add_argument('-j', '--json', help='Path to output JSON file')
    parser.add_argument('-t', '--text', help='Path to output text file')

    args = parser.parse_args()

    # Default paths
    if args.input_file is None:
        input_file = "../books/output/–ò—Å—Ç–æ—Ä–∏—è –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞ –ö–∞–∑_improved.txt"
    else:
        input_file = args.input_file

    # Extract base name for output files
    base_name = os.path.splitext(os.path.basename(input_file))[0]
    base_name = base_name.replace("_improved", "")

    if args.json is None:
        json_file = f"../results/{base_name}_parsed.json"
    else:
        json_file = args.json

    if args.text is None:
        text_file = f"../results/{base_name}_parsed.txt"
    else:
        text_file = args.text

    print(f"üìñ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {input_file}")

    try:
        with open(input_file, "r", encoding="utf-8", errors="ignore") as f:
            text = f.read()
    except FileNotFoundError:
        print(f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª '{input_file}' –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print(f"   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ OCR: cd parsers && python pdf_to_text.py")
        exit(1)

    print("üîÑ –ü–∞—Ä—Å–∏–Ω–≥ –∫–Ω–∏–≥–∏...")
    book = parse_book(text)

    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    save_as_json(book, json_file)
    save_as_text(book, text_file)

    print_statistics(book)

    print("‚úÖ –ì–æ—Ç–æ–≤–æ! –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω.")
    print("\n–°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    print(f"  ‚Ä¢ {json_file} - —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
    print(f"  ‚Ä¢ {text_file} - —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç")
